{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad992b287d4d0ac",
   "metadata": {},
   "source": [
    "# Adaptive Evaluations with Scorebook - Evaluating an OpenAI GPT Model\n",
    "\n",
    "This quick-start guide showcases an adaptive evaluation of OpenAI's GPT-4o Mini model.\n",
    "\n",
    "We recommend that you first see our [getting started quick-start guide]() if you have not done so already, for more of a detailed overview on adaptive testing and setting up Trismik credentials.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Trismik API key**: Generate a Trismik API key from the [Trismik dashboard's settings page](https://app.trismik.com/settings).\n",
    "- **OpenAI API key**: Generate an OpenAI API key from [OpenAI's API Platform](https://openai.com/api/).\n",
    "\n",
    "## Setup Trismik Credentials"
   ]
  },
  {
   "cell_type": "code",
   "id": "14e576282749edb7",
   "metadata": {},
   "source": [
    "# Set your credentials here\n",
    "TRISMIK_API_KEY = \"your-trismik-api-key-here\"\n",
    "OPENAI_API_KEY = \"your-openai-api-key-here\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "700950d039e4c0f6",
   "metadata": {},
   "source": [
    "## Login with Trismik API Key and Create a Project"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "from scorebook import create_project, login\n",
    "\n",
    "# Login to Trismik\n",
    "login(TRISMIK_API_KEY)\n",
    "print(\"✓ Logged in to Trismik\")\n",
    "\n",
    "# Create a project\n",
    "project = create_project(\n",
    "    name = \"Adaptive Evaluation Demo - GPT-4o Mini\",\n",
    "    description= \"A project created as part of Trismik's quick-start guides.\"\n",
    ")\n",
    "\n",
    "print(\"✓ Project created\")\n",
    "print(f\"Project ID: {project.id}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "13084db21e549ccf",
   "metadata": {},
   "source": [
    "## Define an Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "id": "8aa99f513db6241a",
   "metadata": {},
   "source": [
    "from openai import OpenAI\n",
    "from typing import Any, List\n",
    "import string\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def openai_inference(inputs: List[Any], **hyperparameters: Any) -> List[Any]:\n",
    "    \"\"\"Process inputs through OpenAI's API\"\"\"\n",
    "\n",
    "    outputs = []\n",
    "    for idx, input_item in enumerate(inputs):\n",
    "\n",
    "        # Format prompt\n",
    "        choices = input_item.get(\"options\", [])\n",
    "        prompt = (\n",
    "            str(input_item.get(\"question\", \"\"))\n",
    "            + \"\\nOptions:\\n\"\n",
    "            + \"\\n\".join(\n",
    "                f\"{letter}: {choice['text'] if isinstance(choice, dict) else choice}\"\n",
    "                for letter, choice in zip(string.ascii_uppercase, choices)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Build messages for OpenAI API\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": hyperparameters[\"system_message\"]\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "\n",
    "        # Call OpenAI API and extract output from the response\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            output = response.choices[0].message.content.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            output = f\"Error: {str(e)}\"\n",
    "\n",
    "        outputs.append(output)\n",
    "\n",
    "    return outputs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "efa5c3ea791bbcd1",
   "metadata": {},
   "source": [
    "## Run an Adaptive Evaluation\n",
    "\n",
    "For asynchronous inference functions, use Scorebook's `evaluate_async` function. Both `evaluate` and `evaluate_async` are identical except are synchronous/awaitable respectively."
   ]
  },
  {
   "cell_type": "code",
   "id": "3cbf1b2f13d5553e",
   "metadata": {},
   "source": [
    "from scorebook import evaluate\n",
    "\n",
    "# Run adaptive evaluation\n",
    "results = evaluate(\n",
    "    inference = openai_inference,\n",
    "    datasets = \"trismik/figQA:adaptive\",\n",
    "    hyperparameters = {\"system_message\": \"Answer the question with only the letter of the correct option. No additonal text or context\"},\n",
    "    split = \"validation\",\n",
    "    experiment_id = \"Adaptive-Common-Sense-QA-Notebook\",\n",
    "    project_id = project.id,\n",
    ")\n",
    "\n",
    "# Print the adaptive evaluation results\n",
    "print(\"✓ Adaptive evaluation complete!\")\n",
    "print(\"Results: \", results[0][\"score\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Next Steps",
   "id": "d37cb5e87cc297fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
